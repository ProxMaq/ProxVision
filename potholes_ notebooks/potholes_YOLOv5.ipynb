{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "potholes_YOLOv5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqcwMq69qKx1"
      },
      "source": [
        "!nvidia-smi\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULIfUUzu9mK5"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "!pip install -qr yolov5/requirements.txt  # install dependencies (ignore errors)\n",
        "%cd yolov5\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Wsgj11foXO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.unmount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW"
      },
      "source": [
        "# Export code snippet and paste here\n",
        "unzip your dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57nHj3OUG11w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158f0e49-2605-4661-e802-d40e46f8ac58"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Factory Security Automation/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ3DmmGQztJj"
      },
      "source": [
        "# this is the YAML file that we're loading into this notebook with our data\n",
        "#%cat data.yaml\n",
        "\n",
        "%cat data.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eoam-0AWhKEe"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rvt5wilnDyX"
      },
      "source": [
        "#this is the model configuration we will use \n",
        "%cat '../models/yolov5s.yaml'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "source": [
        "%%writetemplate ..yolov5/models/yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. \n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "\n",
        "!python train.py --img 416 --batch 32 --epochs 2000 --data '/content/data.yaml' --cfg '/content/custom_yolov5s.yaml' --weights '' --name yolov5s_results  --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C60XAsyv6OPe"
      },
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.general import plot_results; plot_results()  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/exp0_yolov5s_results/results.png', width=1000)  # view results.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        " Visualize Our Training Data with Labels\n",
        "\n",
        "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF9MLHDb7tB6"
      },
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/drive/SplitUniversity_WEB1.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W40tI99_7BcH"
      },
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/drive/SplitUniversity_WEB1561.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3qM6T0W53gh"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIEwt5YLeQ7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27f2686-9eba-416a-ab53-93c8200b7553"
      },
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mexp0_yolov5s_results\u001b[0m/  \u001b[01;34mexp1_yolov5s_results\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SyOWS80qR32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac62d84-fe1e-465a-b1d5-cd476de223a1"
      },
      "source": [
        "%ls runs/exp1_yolov5s_results/weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best.pt  last.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRhZmqhMqQtQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      },
      "source": [
        "# Saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/exp1_yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source \"/content/drive/test/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKEqYtTgbRc"
      },
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_wg3VeiXMW"
      },
      "source": [
        "%cp /content/yolov5/runs/exp0_yolov5s_results/weights/best.pt /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        ""
      ]
    }
  ]
}