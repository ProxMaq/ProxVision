{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Image Caption Generator 30k.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtUY9CqtH8Mr","executionInfo":{"status":"ok","timestamp":1611760897763,"user_tz":-330,"elapsed":1099,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"286eb8de-e4d0-43af-c58f-f4fa9cac51eb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1A4iDtqINJy","executionInfo":{"status":"ok","timestamp":1611760899031,"user_tz":-330,"elapsed":2346,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"921e0c8c-38a0-4f0b-aeae-445b0a64ad44"},"source":["cd /content/drive/MyDrive/Colab Notebooks/Projects/Flickr30k"],"execution_count":71,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Projects/Flickr30k\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEiMXUReIWrl","executionInfo":{"status":"ok","timestamp":1611760899034,"user_tz":-330,"elapsed":2330,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"0e9570d2-3081-4803-c506-a6fd3982635e"},"source":["!ls"],"execution_count":72,"outputs":[{"output_type":"stream","text":[" descriptions.txt\t\t      models\t   tokenizer.p\n"," features.p\t\t\t     'text file'\n","'Image Caption Generator 30k.ipynb'   text.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EsqbzKYnIaX2","executionInfo":{"status":"ok","timestamp":1611760899037,"user_tz":-330,"elapsed":2316,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"08a79c4d-5357-4bdb-e4b3-ac09c7c7a8ff"},"source":["from zipfile import ZipFile\r\n","\r\n","filename = \"text.zip\"\r\n","\r\n","with ZipFile(filename, 'r') as text:\r\n","  print(\"Importing...\")\r\n","  text.extractall()\r\n","  print(\"Done\")"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Importing...\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsYblNy9J5E8","executionInfo":{"status":"ok","timestamp":1611760899929,"user_tz":-330,"elapsed":3191,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"46fb2ffb-3f17-4a3c-bdc0-11f321a08a34"},"source":["!ls"],"execution_count":74,"outputs":[{"output_type":"stream","text":[" descriptions.txt\t\t      models\t   tokenizer.p\n"," features.p\t\t\t     'text file'\n","'Image Caption Generator 30k.ipynb'   text.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKqBzHOFMeG9","executionInfo":{"status":"ok","timestamp":1611760901779,"user_tz":-330,"elapsed":5025,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"10a0cba7-4bba-49ae-8789-eccc8d226e7a"},"source":["!pip install keras==2.3.1"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zmWMTvZKNKT","executionInfo":{"status":"ok","timestamp":1611760903748,"user_tz":-330,"elapsed":6977,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"fa7a695c-8433-4626-aeeb-360568225138"},"source":["!pip install tensorflow-gpu==2.1.0"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.36.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.12.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.32.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.10.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.19.5)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.2.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n","Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (2.1.1)\n","Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (2.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0) (51.3.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.23.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tu0tJ3_FKX7J","executionInfo":{"status":"ok","timestamp":1611760903751,"user_tz":-330,"elapsed":6963,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"3b6b241c-0513-4274-f1fe-e78941c3de97"},"source":["!nvidia-smi"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Wed Jan 27 15:21:43 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    32W /  70W |   1325MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UPaJH3hvKiWp","executionInfo":{"status":"ok","timestamp":1611760903753,"user_tz":-330,"elapsed":6947,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":[""],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkAQgJdSHiUU","executionInfo":{"status":"ok","timestamp":1611760903756,"user_tz":-330,"elapsed":6933,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"7a355de3-01da-4162-c617-a1e16ac95e40"},"source":["import string\n","import numpy as np\n","from PIL import Image\n","import os\n","from pickle import dump, load\n","from pathlib import Path\n","\n","from keras.applications.xception import Xception, preprocess_input\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical, plot_model\n","from keras.layers.merge import add\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n","\n","#small library for seeing the progress of loops.\n","from tqdm import tqdm\n","tqdm().pandas()"],"execution_count":78,"outputs":[{"output_type":"stream","text":["0it [00:00, ?it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQ-mN5G2RHTy","executionInfo":{"status":"ok","timestamp":1611760903759,"user_tz":-330,"elapsed":6917,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"4370cd18-a8e7-4193-cbbc-924fb9bd1569"},"source":["cd /content/drive/MyDrive/Colab Notebooks/Projects/Flickr30k"],"execution_count":79,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Projects/Flickr30k\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZ2LZ2wIHiUo","executionInfo":{"status":"ok","timestamp":1611760903760,"user_tz":-330,"elapsed":6902,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#from tensorflow.keras import pydot\n","#import pydotplus\n","#import pydot"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHM9IJiQHiUq","executionInfo":{"status":"ok","timestamp":1611760903762,"user_tz":-330,"elapsed":6893,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["# Loading a text file into memory\n","def load_doc(filename):\n","    # Opening the file as read only\n","    file = open(filename,encoding=\"utf8\",mode='r')\n","    text = file.read()\n","    file.close()\n","    return text"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7uTqhhIHiUr","executionInfo":{"status":"ok","timestamp":1611760903763,"user_tz":-330,"elapsed":6878,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["# get all imgs with their captions\n","def all_img_captions(filename):\n","    file = load_doc(filename)\n","    captions = file.split('\\n')\n","    descriptions ={}\n","    for caption in captions[:-1]:\n","        img, caption = caption.split('\\t')\n","        if img[:-2] not in descriptions:\n","            descriptions[img[:-2]] = [caption]\n","        else:\n","            descriptions[img[:-2]].append(caption)\n","    return descriptions"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kf_Dgz6_HiUs","executionInfo":{"status":"ok","timestamp":1611760903764,"user_tz":-330,"elapsed":6866,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["##Data cleaning- lower casing, removing puntuations and words containing numbers\n","def cleaning_text(captions):\n","    table = str.maketrans('','',string.punctuation)\n","    for img,caps in captions.items():\n","        for i,img_caption in enumerate(caps):\n","\n","            img_caption.replace(\"-\",\" \")\n","            desc = img_caption.split()\n","\n","            #converts to lower case\n","            desc = [word.lower() for word in desc]\n","            #remove punctuation from each token\n","            desc = [word.translate(table) for word in desc]\n","            #remove hanging 's and a \n","            desc = [word for word in desc if(len(word)>1)]\n","            #remove tokens with numbers in them\n","            desc = [word for word in desc if(word.isalpha())]\n","            #convert back to string\n","\n","            img_caption = ' '.join(desc)\n","            captions[img][i]= img_caption\n","    return captions"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"4UJnh2e-HiUu","executionInfo":{"status":"ok","timestamp":1611760903766,"user_tz":-330,"elapsed":6853,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["def text_vocabulary(descriptions):\n","    # build vocabulary of all unique words\n","    vocab = set()\n","    \n","    for key in descriptions.keys():\n","        [vocab.update(d.split()) for d in descriptions[key]]\n","    \n","    return vocab"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFIrevmgHiUw","executionInfo":{"status":"ok","timestamp":1611760903767,"user_tz":-330,"elapsed":6840,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#All descriptions in one file \n","def save_descriptions(descriptions, filename):\n","    lines = list()\n","    for key, desc_list in descriptions.items():\n","        for desc in desc_list:\n","            lines.append(key + '\\t' + desc )\n","    data = \"\\n\".join(lines)\n","    file = open(filename,\"w\")\n","    file.write(data)\n","    file.close()"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"4g_F6QazHiUx","executionInfo":{"status":"ok","timestamp":1611760903768,"user_tz":-330,"elapsed":6830,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["# all_train_captions = []\n","# for key, val in descriptions.items():\n","#     for cap in val:\n","#         all_train_captions.append(cap)\n","\n","# # Consider only words which occur at least 8 times in the corpus\n","# word_count_threshold = 8\n","# word_counts = {}\n","# nsents = 0\n","# for sent in all_train_captions:\n","#     nsents += 1\n","#     for w in sent.split(' '):\n","#         word_counts[w] = word_counts.get(w, 0) + 1\n","\n","# vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n","\n","# print('preprocessed words %d ' % len(vocab))\n"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"_EMCenHEHiUy","executionInfo":{"status":"ok","timestamp":1611760903770,"user_tz":-330,"elapsed":6820,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["dataset_text = \"/content/drive/MyDrive/Colab Notebooks/Projects/Flickr30k/text file\"\n","#dataset_images = \"C:\\\\Users\\Harsh\\Desktop\\Minor Project\\Code\\Flickr30k\\Flickr30k_images\""],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"sPYnd6lZHiUz","executionInfo":{"status":"ok","timestamp":1611760906218,"user_tz":-330,"elapsed":9253,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"10d23918-3db7-4d67-e225-899da7f699d1"},"source":["#we prepare our text data\n","filename = dataset_text + \"/\" + \"flickr30k_results.txt\"\n","#loading the file that contains all data\n","#mapping them into descriptions dictionary img to 5 captions\n","descriptions = all_img_captions(filename)\n","print(\"Length of descriptions =\" ,len(descriptions))\n","\n","#cleaning the descriptions\n","clean_descriptions = cleaning_text(descriptions)\n","\n","#building vocabulary \n","vocabulary = text_vocabulary(clean_descriptions)\n","print(\"Length of vocabulary = \", len(vocabulary))\n","\n","#saving each description to file \n","save_descriptions(clean_descriptions, \"descriptions.txt\")"],"execution_count":88,"outputs":[{"output_type":"stream","text":["Length of descriptions = 31783\n","Length of vocabulary =  19735\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"90QcUbSFHiU1","executionInfo":{"status":"ok","timestamp":1611760906220,"user_tz":-330,"elapsed":9240,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#tqdm(os.listdir(directory))"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKJLBLzIHiU2","executionInfo":{"status":"ok","timestamp":1611760906223,"user_tz":-330,"elapsed":9230,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["def extract_features(directory):\n","        model = Xception( include_top=False, weights=\"imagenet\", pooling='avg' )\n","        features = {}\n","        for img in tqdm(os.listdir(directory)):\n","            filename = directory + \"/\" + img\n","            image = Image.open(filename)\n","            image = image.resize((299,299))\n","            image = np.expand_dims(image, axis=0)\n","            #image = preprocess_input(image)\n","            image = image/127.5\n","            image = image - 1.0\n","            \n","            feature = model.predict(image)\n","            features[img] = feature\n","        return features"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"QywWWBnRHiU3","executionInfo":{"status":"ok","timestamp":1611760906224,"user_tz":-330,"elapsed":9217,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#2048 feature vector\n","#features = extract_features(dataset_images)\n","#dump(features, open(\"features.p\",\"wb\"))"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"1NoWsQYYHiU4","executionInfo":{"status":"ok","timestamp":1611760906682,"user_tz":-330,"elapsed":9664,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["features = load(open(\"features.p\",\"rb\"))"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"DV7Qcuy3HiU5","executionInfo":{"status":"ok","timestamp":1611760906684,"user_tz":-330,"elapsed":9653,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#load the data\n","def load_doc_encode(filename):\n","    # Opening the file as read only\n","    file = open(filename,encoding='ISO-8859-1',mode='r')\n","    text = file.read()\n","    file.close()\n","    return text\n","\n","def load_photos(filename):\n","    file = load_doc_encode(filename)\n","    photos = file.split(\"\\n\")[:-1]\n","    return photos\n","\n","\n","def load_clean_descriptions(filename, photos):   \n","    #loading clean_descriptions\n","    file = load_doc_encode(filename)\n","    descriptions = {}\n","    for line in file.split(\"\\n\"):\n","        \n","        words = line.split()\n","        if len(words)<1 :\n","            continue\n","    \n","        image, image_caption = words[0], words[1:]\n","        \n","        if image in photos:\n","            if image not in descriptions:\n","                descriptions[image] = []\n","            desc = '<start> ' + \" \".join(image_caption) + ' <end>'\n","            descriptions[image].append(desc)\n","\n","    return descriptions\n","\n","\n","def load_features(photos):\n","    #loading all features\n","    all_features = load(open(\"features.p\",\"rb\"))\n","    #selecting only needed features\n","    features = {k:all_features[k] for k in photos}\n","    return features\n"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"i83ijnFyHiU6","executionInfo":{"status":"ok","timestamp":1611761082360,"user_tz":-330,"elapsed":185317,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["filename = dataset_text + \"/\" + \"Descriptions_train.txt\"\n","\n","#train = loading_data(filename)\n","train_imgs = load_photos(filename)\n","train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n","train_features = load_features(train_imgs)"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKfm4gxIHiU7","executionInfo":{"status":"ok","timestamp":1611761082362,"user_tz":-330,"elapsed":185308,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#converting dictionary to clean list of descriptions\n","def dict_to_list(descriptions):\n","    all_desc = []\n","    for key in descriptions.keys():\n","        [all_desc.append(d) for d in descriptions[key]]\n","    return all_desc\n","\n","#creating tokenizer class \n","#this will vectorise text corpus\n","#each integer will represent token in dictionary \n","\n","from keras.preprocessing.text import Tokenizer\n","\n","def create_tokenizer(descriptions):\n","    desc_list = dict_to_list(descriptions)\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(desc_list)\n","    return tokenizer\n"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq3JMT1THiU8","executionInfo":{"status":"ok","timestamp":1611761084454,"user_tz":-330,"elapsed":187384,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"fcef2dbb-d201-4e2d-8c6d-23db9c6134ce"},"source":["# give each word a index, and store that into tokenizer.p pickle file\n","tokenizer = create_tokenizer(train_descriptions)\n","dump(tokenizer, open('tokenizer.p', 'wb'))\n","vocab_size = len(tokenizer.word_index) + 1\n","vocab_size "],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19736"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5kFUfBVHiU-","executionInfo":{"status":"ok","timestamp":1611761084456,"user_tz":-330,"elapsed":187369,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"760b1aec-0abd-4807-9e74-a9048e47e8a5"},"source":["\n","#calculate maximum length of descriptions\n","def max_length(descriptions):\n","    desc_list = dict_to_list(descriptions)\n","    return max(len(d.split()) for d in desc_list)\n","\n","max_length = max_length(descriptions)\n","max_length"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["72"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"a9NTirXfHiU_","executionInfo":{"status":"ok","timestamp":1611761084458,"user_tz":-330,"elapsed":187356,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#features['1000268201_693b08cb0e.jpg'][0]"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMvmNegBHiVA","executionInfo":{"status":"ok","timestamp":1611761084460,"user_tz":-330,"elapsed":187344,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["# Define the model\n","\n","#1 Photo feature extractor - we extracted features from pretrained model Xception. \n","#2 Sequence processor - word embedding layer that handles text, followed by LSTM \n","#3 Decoder - Both 1 and 2 model produce fixed length vector. They are merged together and processed by dense layer to make final prediction"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEDAqqoQHiVA","executionInfo":{"status":"ok","timestamp":1611761084462,"user_tz":-330,"elapsed":187334,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["#create input-output sequence pairs from the image description.\n","\n","#data generator, used by model.fit_generator()\n","def data_generator(descriptions, features, tokenizer, max_length):\n","    while 1:\n","        for key, description_list in descriptions.items():\n","            #retrieve photo features\n","            feature = features[key][0]\n","            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, feature)\n","            yield [[input_image, input_sequence], output_word]         \n","\n","def create_sequences(tokenizer, max_length, desc_list, feature):\n","    X1, X2, y = list(), list(), list()\n","    # walk through each description for the image\n","    for desc in desc_list:\n","        # encode the sequence\n","        seq = tokenizer.texts_to_sequences([desc])[0]\n","        # split one sequence into multiple X,y pairs\n","        for i in range(1, len(seq)):\n","            # split into input and output pair\n","            in_seq, out_seq = seq[:i], seq[i]\n","            # pad input sequence\n","            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","            # encode output sequence\n","            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","            # store\n","            X1.append(feature)\n","            X2.append(in_seq)\n","            y.append(out_seq)\n","    return np.array(X1), np.array(X2), np.array(y)"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPh8DWKMHiVB","executionInfo":{"status":"ok","timestamp":1611761084462,"user_tz":-330,"elapsed":187319,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}},"outputId":"fa1fa865-4578-4f4e-baf9-1103146ba9fb"},"source":["[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n","a.shape, b.shape, c.shape"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((52, 2048), (52, 72), (52, 19736))"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"id":"2GfRdxW8HiVC","executionInfo":{"status":"ok","timestamp":1611761084466,"user_tz":-330,"elapsed":187309,"user":{"displayName":"Harsh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvqO-5LSN_g8vM_6bdkHdAhLCq47Qsj1sh3pItYA=s64","userId":"10935812418543396484"}}},"source":["from keras.utils import plot_model\n","\n","# define the captioning model\n","def define_model(vocab_size, max_length):\n","    \n","    # features from the CNN model squeezed from 2048 to 256 nodes\n","    inputs1 = Input(shape=(2048,))\n","    fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(fe1)\n","\n","    # LSTM sequence model\n","    inputs2 = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    se2 = Dropout(0.5)(se1)\n","    se3 = LSTM(256)(se2)\n","\n","    # Merging both models\n","    decoder1 = add([fe2, se3])\n","    decoder2 = Dense(256, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","    \n","    # tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n","    \n","    # summarize model\n","    #print(model.summary())\n","    #plot_model(model, to_file='model.png', show_shapes=True)\n","    \n","    return model"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"RFe8rt8AHiVD","outputId":"9e9faddc-5004-4271-d750-a1ced6c0944a"},"source":["# train our model\n","print('Dataset: ', len(train_imgs))\n","print('Descriptions: train=', len(train_descriptions))\n","print('Photos: train=', len(train_features))\n","print('Vocabulary Size:', vocab_size)\n","print('Description Length: ', max_length)\n","\n","model = define_model(vocab_size, max_length)\n","epochs = 10\n","steps = len(train_descriptions)\n","# making a directory models to save our models\n","#os.mkdir(\"models\")\n","for i in range(epochs):\n","    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n","    model.fit(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n","    model.save(\"models/model_\" + str(i) + \".h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset:  158914\n","Descriptions: train= 31783\n","Photos: train= 31783\n","Vocabulary Size: 19736\n","Description Length:  72\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","31783/31783 [==============================] - 2813s 89ms/step - loss: 4.3848 - acc: 0.2558\n","Epoch 1/1\n","31783/31783 [==============================] - 2816s 89ms/step - loss: 3.9826 - acc: 0.2837\n","Epoch 1/1\n","31783/31783 [==============================] - 2812s 88ms/step - loss: 3.9184 - acc: 0.2893\n","Epoch 1/1\n","31783/31783 [==============================] - 2812s 88ms/step - loss: 3.9001 - acc: 0.2918\n","Epoch 1/1\n","31783/31783 [==============================] - 2818s 89ms/step - loss: 3.8973 - acc: 0.2930\n","Epoch 1/1\n","31783/31783 [==============================] - 2808s 88ms/step - loss: 3.9014 - acc: 0.2936\n","Epoch 1/1\n","31783/31783 [==============================] - 2809s 88ms/step - loss: 3.9077 - acc: 0.2942\n","Epoch 1/1\n","31783/31783 [==============================] - 2806s 88ms/step - loss: 3.9155 - acc: 0.2941\n","Epoch 1/1\n","31783/31783 [==============================] - 2815s 89ms/step - loss: 3.9254 - acc: 0.2942\n","Epoch 1/1\n","26416/31783 [=======================>......] - ETA: 7:53 - loss: 3.8894 - acc: 0.2972"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0qKEUjWfHiVD"},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.applications.xception import Xception\n","from keras.models import load_model\n","from pickle import load\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import argparse\n","from pathlib import Path\n","\n","\n","#ap = argparse.ArgumentParser()\n","#ap.add_argument('-i', '--image', required=True, help=\"Image Path\")\n","#args = vars(ap.parse_args())\n","#img_path = args['image']\n","\n","def extract_features(filename, model):\n","        try:\n","            image = Image.open(filename)\n","            \n","        except:\n","            print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n","        image = image.resize((299,299))\n","        image = np.array(image)\n","        # for images that has 4 channels, we convert them into 3 channels\n","        if image.shape[2] == 4: \n","            image = image[..., :3]\n","        image = np.expand_dims(image, axis=0)\n","        image = image/127.5\n","        image = image - 1.0\n","        feature = model.predict(image)\n","        return feature\n","\n","def word_for_id(integer, tokenizer):\n"," for word, index in tokenizer.word_index.items():\n","     if index == integer:\n","         return word\n"," return None\n","\n","\n","def generate_desc(model, tokenizer, photo, max_length):\n","    in_text = 'start'\n","    for i in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        pred = model.predict([photo,sequence], verbose=0)\n","        pred = np.argmax(pred)\n","        word = word_for_id(pred, tokenizer)\n","        if word is None:\n","            break\n","        in_text += ' ' + word\n","        if word == 'end':\n","            break\n","    return in_text\n","\n","path = Path(\"C:\\\\Users\\Harsh\\Desktop\\Minor Project\\python-project-image-caption-generator\\Flicker8k_Dataset\")\n","img_path = path / '58357057_dea882479e.jpg'\n","max_length = 32\n","tokenizer = load(open(\"tokenizer.p\",\"rb\"))\n","model = load_model('models/model_9.h5')\n","xception_model = Xception(include_top=False, pooling=\"avg\")\n","\n","photo = extract_features(img_path, xception_model)\n","img = Image.open(img_path)\n","\n","description = generate_desc(model, tokenizer, photo, max_length)\n","print(\"\\n\\n\")\n","print(description)\n","plt.imshow(img)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s8ZslbJHiVF"},"source":[""],"execution_count":null,"outputs":[]}]}